{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Prepare and Validate the Dataset\n",
        "\n",
        "### Download the dataset\n",
        "\n",
        "We will work with the [CoEdIT dataset](https://huggingface.co/datasets/grammarly/coedit) of text editing examples (Raheja, et al). In each example, the user asks a writing assistant to rewrite text to suit a specific task (editing fluency, coherence, clarity, or style) and receives a response.\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "\n",
        "{\n",
        " \"_id\": \"57241\",\n",
        " \"task\": \"coherence\",\n",
        " \"src\": \"Make the text more coherent: It lasted for 60 minutes. It featured the three men taking questions from a studio audience.\",\n",
        " \"tgt\": \"Lasting for 60 minutes, it featured the three men taking questions from a studio audience.\"\n",
        "}\n",
        "\n",
        "{\n",
        " \"_id\": \"69028\",\n",
        " \"task\": \"clarity\",\n",
        " \"src\": \"Make the sentence clearer: URLe Lilanga (1934 27 June 2005) was a Tanzanian painter and sculptor, active from the late 1970s and until the early years of the 21st century.\",\n",
        " \"tgt\": \"URLe Lilanga (1934 27 June 2005) was a Tanzanian painter and sculptor, active from the late 1970s and until the early 21st century.\"\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "We will use the src and tgt fields from each example, which correspond to the user’s prompt and the writing assistant’s response, respectively. Instead of using the full dataset, we will use a subset focused on making text coherent: 927 total conversations.\n",
        "\n",
        "To format the dataset for the Python SDK, we create a .jsonl where each JSON object is a conversation containing a series of messages.\n",
        "\n",
        "A System message in the beginning, acting as the preamble that guides the whole conversation\n",
        "Multiple pairs of User and Chatbot messages, representing the conversation that takes place between a human user and a chatbot. Here is a preview of the prepared dataset:\n",
        "\n",
        "```\n",
        "{'messages':\n",
        " [{'role': 'System',\n",
        "   'content': 'You are a writing assistant that helps the user write coherent text.'\n",
        "  },\n",
        "  {'role': 'User',\n",
        "   'content': 'Make the text more coherent: It lasted for 60 minutes. It featured the three men taking questions from a studio audience.'\n",
        "  },\n",
        "  {'role': 'Chatbot',\n",
        "   'content': 'Lasting for 60 minutes, it featured the three men taking questions from a studio audience.'\n",
        "  }\n",
        " ]\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ccdMsADJdDaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNI8LAjwc4Rv",
        "outputId": "c0281e0d-d628-4da5-d7b4-ed77d586e6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/249.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m245.8/249.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/3.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install cohere jsonlines -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import os\n",
        "import json\n",
        "import jsonlines"
      ],
      "metadata": {
        "id": "KFQLQJ8PegkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co = cohere.ClientV2(\"VKxoCS7wrKZgmI7GMtm0OTpDYNNoFGDw3mKEdQQT\")"
      ],
      "metadata": {
        "id": "uOh7ajSLejGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyAARrVqoRdQ",
        "outputId": "20c56e25-42e6-48df-87f5-c656414345a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m409.6/480.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "! wget \"https://huggingface.co/datasets/grammarly/coedit/resolve/main/train.jsonl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYO0-_Ubere3",
        "outputId": "104d6db4-a33e-4226-fe70-e3b2cde8048a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-03 13:55:14--  https://huggingface.co/datasets/grammarly/coedit/resolve/main/train.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 3.169.137.19, 3.169.137.119, 3.169.137.5, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.169.137.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/30/91/3091c2c741f77a2f5aa8986b13e4fb2c3658ab3ebc30ecaa5f6890e60939bdf9/2913249158d6a178dc638e870212ff8a432d128eb6b4bdbe969ee805e6063ce3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.jsonl%3B+filename%3D%22train.jsonl%22%3B&Expires=1733493314&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzQ5MzMxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zMC85MS8zMDkxYzJjNzQxZjc3YTJmNWFhODk4NmIxM2U0ZmIyYzM2NThhYjNlYmMzMGVjYWE1ZjY4OTBlNjA5MzliZGY5LzI5MTMyNDkxNThkNmExNzhkYzYzOGU4NzAyMTJmZjhhNDMyZDEyOGViNmI0YmRiZTk2OWVlODA1ZTYwNjNjZTM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=UXEXAWn3mTcCsiPirCLWB0yyi2I6WMMI49Ex-PmEar3zZ8V9V7WMWGBJKsdTqV6F4Mq0deehzSVlWkI5f9hrbGl83jO0nhMBr3mhirbi-EJB3-ubE7s-QFSjS0bvqiZHQF4dNcYu2DnHq5jpcTo29LpINb4kdw6g8VtLVTOARjBhmB59Ek8BDGGiS7a5vIGUSqXqdumLSX7d4MBSIVrJbzZ0DzxkxLEKQ68u3p124g1fu9pwgBAh181wz-P3dA-1I%7ERLi%7EdAExEAFADxtTJ8FTfpjRtWVQdQGUBoqIKWXQvYIJ0atCXvnb3Ja6OdFyyN%7E6gV7Dr7idZ1OrtU564zeQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-03 13:55:14--  https://cdn-lfs.hf.co/repos/30/91/3091c2c741f77a2f5aa8986b13e4fb2c3658ab3ebc30ecaa5f6890e60939bdf9/2913249158d6a178dc638e870212ff8a432d128eb6b4bdbe969ee805e6063ce3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.jsonl%3B+filename%3D%22train.jsonl%22%3B&Expires=1733493314&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzQ5MzMxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zMC85MS8zMDkxYzJjNzQxZjc3YTJmNWFhODk4NmIxM2U0ZmIyYzM2NThhYjNlYmMzMGVjYWE1ZjY4OTBlNjA5MzliZGY5LzI5MTMyNDkxNThkNmExNzhkYzYzOGU4NzAyMTJmZjhhNDMyZDEyOGViNmI0YmRiZTk2OWVlODA1ZTYwNjNjZTM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=UXEXAWn3mTcCsiPirCLWB0yyi2I6WMMI49Ex-PmEar3zZ8V9V7WMWGBJKsdTqV6F4Mq0deehzSVlWkI5f9hrbGl83jO0nhMBr3mhirbi-EJB3-ubE7s-QFSjS0bvqiZHQF4dNcYu2DnHq5jpcTo29LpINb4kdw6g8VtLVTOARjBhmB59Ek8BDGGiS7a5vIGUSqXqdumLSX7d4MBSIVrJbzZ0DzxkxLEKQ68u3p124g1fu9pwgBAh181wz-P3dA-1I%7ERLi%7EdAExEAFADxtTJ8FTfpjRtWVQdQGUBoqIKWXQvYIJ0atCXvnb3Ja6OdFyyN%7E6gV7Dr7idZ1OrtU564zeQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.169.121.78, 3.169.121.44, 3.169.121.124, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.169.121.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19695735 (19M) [binary/octet-stream]\n",
            "Saving to: ‘train.jsonl’\n",
            "\n",
            "train.jsonl         100%[===================>]  18.78M  24.1MB/s    in 0.8s    \n",
            "\n",
            "2024-12-03 13:55:15 (24.1 MB/s) - ‘train.jsonl’ saved [19695735/19695735]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get a subset of the dataset\n",
        "\n",
        "Instead of using the full dataset, we will use a subset focused on making text coherent: 927 total conversations."
      ],
      "metadata": {
        "id": "Dws3ZeClfjhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use subset of the dataset focused on making text more coherent\n",
        "phrase = \"coherent\"\n",
        "\n",
        "# instantiate python list where we will store correct subset of dataset\n",
        "dataset_list = []\n",
        "\n",
        "# create subset of dataset\n",
        "with jsonlines.open('train.jsonl') as f:\n",
        "    for line in f.iter():\n",
        "        if phrase in line['src'].split(\":\")[0]:\n",
        "            dataset_list.append(line)\n",
        "\n",
        "# Split data into training and test\n",
        "dataset_list_train = dataset_list[:800]\n",
        "dataset_list_test = dataset_list[800:]\n",
        "\n",
        "print(\"Total number of examples:\", len(dataset_list))\n",
        "print(\"Number of examples in training set:\", len(dataset_list_train))\n",
        "print(\"Number of examples in the test set:\", len(dataset_list_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DjOtBBkfAFn",
        "outputId": "1c16d651-ed9f-4a20-988c-e36fc4324bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of examples: 927\n",
            "Number of examples in training set: 800\n",
            "Number of examples in the test set: 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview the dataset\n",
        "\n",
        "We will use the `src` and `tgt` fields from each example, which correspond to the user’s prompt and the writing assistant’s response, respectively."
      ],
      "metadata": {
        "id": "w_fJwsdzfrkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first ten prompts and corresponding responses\n",
        "for item in dataset_list_train[:10]:\n",
        "    print(item[\"src\"])\n",
        "    print(item[\"tgt\"])\n",
        "    print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkzchj3hfnQM",
        "outputId": "739383b3-679c-4ada-e7ca-3b3c98a45cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make the text coherent: The Bank's main strategy is to further expand its network and increase its lending activities with particular focus on the SME sector. The EBRD helps Bank, by developing and financing Bank's portfolio of and strengthening the bank's funding base.\n",
            "The Bank's main strategy is to further expand its network and increase its lending activities with particular focus on the SME sector. The EBRD helps Union Bank, by developing and financing its portfolio of and strengthening the bank's funding base.\n",
            "--------------------------------------------------\n",
            "Make the text coherent: It was not illegal under international law ; captured foreign sailors were released. Confederates went to prison camps.\n",
            "It was not illegal under international law ; captured foreign sailors were released, while Confederates went to prison camps.\n",
            "--------------------------------------------------\n",
            "Make the text coherent: The Union blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried Union.\n",
            "The Union blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried it.\n",
            "--------------------------------------------------\n",
            "Make the text more coherent: It lasted for 60 minutes. It featured the three men taking questions from a studio audience.\n",
            "Lasting for 60 minutes, it featured the three men taking questions from a studio audience.\n",
            "--------------------------------------------------\n",
            "Make the text more coherent: The Security Council could not decide on a Secretary-General. The Third World countries would not nominate any other candidates as long as Salim remained in the race.\n",
            "The Security Council could not decide on a Secretary-General, but the Third World countries would not nominate any other candidates as long as Salim remained in the race.\n",
            "--------------------------------------------------\n",
            "Make the text coherent: All of the 2011 inductees lost their lives in the 1961 crash of Sabena Flight 548, considered to be the most tragic event in figure skating history. inductees were honored posthumously in observance of the fiftieth anniversary of the tragedy.\n",
            "All of the 2011 inductees lost their lives in the 1961 crash of Sabena Flight 548, considered to be the most tragic event in figure skating history. They were honored posthumously in observance of the fiftieth anniversary of the tragedy.\n",
            "--------------------------------------------------\n",
            "Make the text more coherent: Foreign Service personnel stationed in nations with inadequate public infrastructure also face greater risk of injury or death due to fire, traffic accidents, and natural disasters. An FSO was one of the first identified victims of the 2010 Haiti earthquake.\n",
            "Foreign Service personnel stationed in nations with inadequate public infrastructure also face greater risk of injury or death due to fire, traffic accidents, and natural disasters. For instance, an FSO was one of the first identified victims of the 2010 Haiti earthquake.\n",
            "--------------------------------------------------\n",
            "Make the text more coherent: The Federalist Party made a relatively strong showing, winning seats in both chambers while supporting a competitive challenge to the incumbent Democratic-Republican President. The Democratic-Republican continued Democratic-Republican's control of the Presidency and both houses of Congress.\n",
            "The Federalist Party made a relatively strong showing, winning seats in both chambers while supporting a competitive challenge to the incumbent Democratic-Republican President. However, the Democratic-Republican Party continued its control of the Presidency and both houses of Congress.\n",
            "--------------------------------------------------\n",
            "Make the text coherent: Since the 1990s, Loughborough University operated a satellite higher education campus in Peterborough. This closed in 2003, leaving the city as one of the largest urban areas in the country without a dedicated provision of higher education.\n",
            "Since the 1990s, Loughborough University operated a satellite higher education campus in Peterborough. However, this closed in 2003, leaving the city as one of the largest urban areas in the country without a dedicated provision of higher education.\n",
            "--------------------------------------------------\n",
            "Make the text coherent: The cancer center is named after Monroe Dunaway Anderson, a banker and cotton trader from Jackson, Tennessee. Monroe Dunaway Anderson was a banker of a business partnership with Monroe Dunaway Anderson's brother-in-law Will Clayton.\n",
            "The cancer center is named after Monroe Dunaway Anderson, a banker and cotton trader from Jackson, Tennessee. He was a member of a business partnership with his brother-in-law Will Clayton.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the dataset for Cohere's Chat endpoint\n",
        "\n",
        "To format the dataset for the Chat endpoint, we create a `.jsonl` where each JSON object is a conversation containing a series of messages.\n",
        "- A `System` message in the beginning that guides the whole conversation\n",
        "- Multiple pairs of `User` and `Chatbot` messages, representing the conversation that takes place between a human user and a chatbot"
      ],
      "metadata": {
        "id": "jmCBED7Tf3rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# arranges the data to suit Cohere's format\n",
        "def create_chat_ft_data(system_message, user_message, chatbot_message):\n",
        "    formatted_data = {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"System\",\n",
        "                \"content\": system_message\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"User\",\n",
        "                \"content\": user_message\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"Chatbot\",\n",
        "                \"content\": chatbot_message\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return formatted_data\n",
        "\n",
        "system_message = \"You are a writing assistant that helps the user write coherent text.\""
      ],
      "metadata": {
        "id": "2KO7ig47fuov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates jsonl file from list of examples\n",
        "def create_jsonl_from_list(file_name, dataset_segment, system_message):\n",
        "    path = f'{file_name}.jsonl'\n",
        "    if not os.path.isfile(path):\n",
        "        with open(path, 'w+') as file:\n",
        "            for item in dataset_segment:\n",
        "                user_message = item[\"src\"]\n",
        "                chatbot_message = item[\"tgt\"]\n",
        "                formatted_data = create_chat_ft_data(system_message, user_message, chatbot_message)\n",
        "                file.write(json.dumps(formatted_data) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "# Create training jsonl file\n",
        "file_name = \"coedit_coherence_train\"\n",
        "create_jsonl_from_list(file_name, dataset_list_train, system_message)\n",
        "\n",
        "# List the first 3 items in the JSONL file\n",
        "with jsonlines.open(f'{file_name}.jsonl') as f:\n",
        "    [print(line) for _, line in zip(range(3), f)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtsXvWodiQeQ",
        "outputId": "2c6cac61-971d-4c06-d140-edf46c9beec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [{'role': 'System', 'content': 'You are a writing assistant that helps the user write coherent text.'}, {'role': 'User', 'content': \"Make the text coherent: The Bank's main strategy is to further expand its network and increase its lending activities with particular focus on the SME sector. The EBRD helps Bank, by developing and financing Bank's portfolio of and strengthening the bank's funding base.\"}, {'role': 'Chatbot', 'content': \"The Bank's main strategy is to further expand its network and increase its lending activities with particular focus on the SME sector. The EBRD helps Union Bank, by developing and financing its portfolio of and strengthening the bank's funding base.\"}]}\n",
            "{'messages': [{'role': 'System', 'content': 'You are a writing assistant that helps the user write coherent text.'}, {'role': 'User', 'content': 'Make the text coherent: It was not illegal under international law ; captured foreign sailors were released. Confederates went to prison camps.'}, {'role': 'Chatbot', 'content': 'It was not illegal under international law ; captured foreign sailors were released, while Confederates went to prison camps.'}]}\n",
            "{'messages': [{'role': 'System', 'content': 'You are a writing assistant that helps the user write coherent text.'}, {'role': 'User', 'content': \"Make the text coherent: The Union blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried Union.\"}, {'role': 'Chatbot', 'content': \"The Union blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of very few lives. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried it.\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Use/Evaluate the Fine-Tuned Model\n",
        "\n"
      ],
      "metadata": {
        "id": "yCG9AR5zw7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Test Data"
      ],
      "metadata": {
        "id": "zRLs7ro8xmMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you're ready to use the fine-tuned model, navigate to the API tab. There, you'll see the model ID that you should use when calling `co.chat()`.\n",
        "\n",
        "<img src=\"https://files.readme.io/82c726e-get_model_id.png\">\n",
        "\n",
        "In the following code, we supply the first three messages from the test dataset to both the pre-trained and fine-tuned models for comparison."
      ],
      "metadata": {
        "id": "Q2fcdlM1xpNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset_list_test[:1]:\n",
        "    # User prompt\n",
        "    user_message = item[\"src\"]\n",
        "    # Desired/target response from dataset\n",
        "    tgt_message = item[\"tgt\"]\n",
        "\n",
        "    # Get default model response\n",
        "    response_pretrained = co.chat(\n",
        "        model=\"command-r-plus\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Get fine-tuned model response\n",
        "    response_finetuned = co.chat(\n",
        "        model=\"ca08b7a8-eaad-4fd1-b1fa-2427cb2ce1a6-ft\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"User: {user_message}\",\"\\n-----\")\n",
        "    print(f\"Desired response: {tgt_message}\",\"\\n-----\")\n",
        "    # Accessing the text from the first element of the list\n",
        "    print(f\"Default model's response: {response_pretrained.message.content[0].text}\",\"\\n-----\")\n",
        "    # Accessing the text from the first element of the list\n",
        "    print(f\"Fine-tuned model's response: {response_finetuned.message.content[0].text}\")\n",
        "    print(\"-\"*100,\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUavbgllxBb4",
        "outputId": "c8dd09ef-bae7-4d56-8221-d72f62532980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Make the text more coherent: We do know that at the end of the Muromachi period it stopped appearing in written records. That Muromachi burned down many times, the last we know of in 1405. \n",
            "-----\n",
            "Desired response: We do know that at the end of the Muromachi period it stopped appearing in written records and that it burned down many times, the last we know of in 1405. \n",
            "-----\n",
            "Default model's response: We do know that at the end of the Muromachi period, specifically after 1405 (the year of the last recorded fire), it stopped appearing in written records. This may be due to the fact that Muromachi burned down many times. \n",
            "-----\n",
            "Fine-tuned model's response: We do know that at the end of the Muromachi period it stopped appearing in written records, although the district burned down many times, the last we know of in 1405.\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"ca08b7a8-eaad-4fd1-b1fa-2427cb2ce1a6-ft\"\n",
        "\n",
        "def run_chat(user_message, messages=None):\n",
        "    # Initialize messages as an empty list if None is passed\n",
        "    if messages is None:\n",
        "        messages = []\n",
        "\n",
        "    # Check if system message already exists\n",
        "    if not any(m.get('role') == 'system' for m in messages):\n",
        "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "\n",
        "    # Generate response\n",
        "    response = co.chat(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Print the response\n",
        "    print(response.message.content)\n",
        "\n",
        "    # Append the turn to the chat history\n",
        "    messages.extend([\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "        {\"role\": \"assistant\", \"content\": response.message.content[0].text}\n",
        "    ])\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "7U1jliDPzuvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = run_chat(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpQLR1GH1cZL",
        "outputId": "306e7872-5512-4175-8c37-cfa269b0aa3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you?')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = run_chat(\"I'm fine. Can I ask you for help with some tasks?\", messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmLQNSfA1f2j",
        "outputId": "0846b460-8795-4858-a4a3-a8c793ef0dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextAssistantMessageResponseContentItem(type='text', text='Sure, what do you need help with?')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = run_chat(\"Make this more coherent: Manuel now has to decide-will he let his best friend be happy with her Prince Charming. Or will he fight for the love that has kept him alive for the last 16 years?\", messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf3BhGlw2mL6",
        "outputId": "9fccc7b2-69c8-47fb-ed6b-a241fad289bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextAssistantMessageResponseContentItem(type='text', text='Manuel now has to decide-will he let his best friend be happy with her Prince Charming, or will he fight for the love that has kept him alive for the last 16 years?')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = run_chat(\"Help me with this one - She left Benaras. Conditions back home were bad.\", messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdkQnS6X2s43",
        "outputId": "e63d92b0-05ae-4b22-e09f-f253ca4a792f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextAssistantMessageResponseContentItem(type='text', text='Leaving Benaras, conditions back home were bad.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9PjOZDG21FP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}