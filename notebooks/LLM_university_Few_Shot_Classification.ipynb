{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPoSTwY2EYeJ",
        "outputId": "51da7ae2-4b72-4f94-ed9b-4b5706447c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.13.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.13.0 fastavro-1.9.7 httpx-sse-0.4.0 parameterized-0.9.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ],
      "source": [
        "%pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wrnZB6w5Efnf"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "from cohere import ClassifyExample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3b82k02_Ey6C"
      },
      "outputs": [],
      "source": [
        "co = cohere.Client('COHERE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUZqxN5SFDa-"
      },
      "source": [
        "# Step 1: Prepare Examples and Input\n",
        "\n",
        "A typical machine learning model requires many training examples to perform text classification, but with the Classify endpoint, you can get started with as few as two examples per class. You need to prepare the following:\n",
        "\n",
        "Examples\n",
        "\n",
        "These are the training examples we give the model to show the output we want it to generate.\n",
        "Each example contains the text itself and the corresponding label, or class.\n",
        "The minimum number of examples required is two per class.\n",
        "You can have as many classes as possible. If you are classifying text into two classes, that means you need a minimum of four examples, and if you have three, that means you need six examples, and so on.\n",
        "\n",
        "Our sentiment analysis classifier has three classes with five examples each: “Positive” for a positive sentiment, “Negative” for a negative sentiment, and “Neutral” for a neutral sentiment. The code looks as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RUvaBZ90FCo3"
      },
      "outputs": [],
      "source": [
        "examples = [ClassifyExample(text=\"I’m so proud of you\", label=\"positive\"),\n",
        "            ClassifyExample(text=\"What a great time to be alive\", label=\"positive\"),\n",
        "            ClassifyExample(text=\"That’s awesome work\", label=\"positive\"),\n",
        "            ClassifyExample(text=\"The service was amazing\", label=\"positive\"),\n",
        "            ClassifyExample(text=\"I love my family\", label=\"positive\"),\n",
        "            ClassifyExample(text=\"They don't care about me\", label=\"negative\"),\n",
        "            ClassifyExample(text=\"I hate this place\", label=\"negative\"),\n",
        "            ClassifyExample(text=\"The most ridiculous thing I've ever heard\", label=\"negative\"),\n",
        "            ClassifyExample(text=\"I am really frustrated\", label=\"negative\"),\n",
        "            ClassifyExample(text=\"This is so unfair\", label=\"negative\"),\n",
        "            ClassifyExample(text=\"This made me think\", label=\"neutral\"),\n",
        "            ClassifyExample(text=\"The good old days\", label=\"neutral\"),\n",
        "            ClassifyExample(text=\"What's the difference\", label=\"neutral\"),\n",
        "            ClassifyExample(text=\"You can't ignore this\", label=\"neutral\"),\n",
        "            ClassifyExample(text=\"That's how I see it\", label=\"neutral\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ek1Z0vhCFibU"
      },
      "outputs": [],
      "source": [
        "inputs = [\"Hello, world! What a beautiful day\",\n",
        "          \"It was a great time with great people\",\n",
        "          \"Great place to work\",\n",
        "          \"That was a wonderful evening\",\n",
        "          \"Maybe this is why\",\n",
        "          \"Let's start again\",\n",
        "          \"That's how I see it\",\n",
        "          \"These are all facts\",\n",
        "          \"This is the worst thing\",\n",
        "          \"I cannot stand this any longer\",\n",
        "          \"This is really annoying\",\n",
        "          \"I am just plain fed up\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ZNcSdQFvhA"
      },
      "source": [
        "# Step 2: Generate Predictions\n",
        "\n",
        "With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For the Classify endpoint, we need to use an embedding model, and we'll useembed-english-v3.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mmFDna_mFrVh"
      },
      "outputs": [],
      "source": [
        "#putting it all together\n",
        "def classify_text(inputs, examples):\n",
        "  \"\"\"\n",
        "    Classifies a list of input texts given the examples\n",
        "    Arguments:\n",
        "        model (str): identifier of the model\n",
        "        inputs (list[str]): a list of input texts to be classified\n",
        "        examples (list[Example]): a list of example texts and class labels\n",
        "    Returns:\n",
        "        classifications (list): each result contains the text, labels, and conf values\n",
        "    \"\"\"\n",
        "  response = co.classify(\n",
        "        model = 'embed-english-v3.0',\n",
        "        inputs = inputs,\n",
        "        examples = examples\n",
        "\n",
        "    )\n",
        "  return response.classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3-Q9QCZ2Gybw"
      },
      "outputs": [],
      "source": [
        "#classify the inputs\n",
        "predictions = classify_text(inputs, examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAEEHLvCG87-",
        "outputId": "ff020cd1-2fd1-416e-8d11-108c1311a868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Hello, world! What a beautiful day\n",
            "Prediction: positive\n",
            "Confidence: 0.40\n",
            "----------\n",
            "Input: It was a great time with great people\n",
            "Prediction: positive\n",
            "Confidence: 0.49\n",
            "----------\n",
            "Input: Great place to work\n",
            "Prediction: positive\n",
            "Confidence: 0.50\n",
            "----------\n",
            "Input: That was a wonderful evening\n",
            "Prediction: positive\n",
            "Confidence: 0.48\n",
            "----------\n",
            "Input: Maybe this is why\n",
            "Prediction: neutral\n",
            "Confidence: 0.45\n",
            "----------\n",
            "Input: Let's start again\n",
            "Prediction: neutral\n",
            "Confidence: 0.42\n",
            "----------\n",
            "Input: That's how I see it\n",
            "Prediction: neutral\n",
            "Confidence: 0.53\n",
            "----------\n",
            "Input: These are all facts\n",
            "Prediction: neutral\n",
            "Confidence: 0.41\n",
            "----------\n",
            "Input: This is the worst thing\n",
            "Prediction: negative\n",
            "Confidence: 0.52\n",
            "----------\n",
            "Input: I cannot stand this any longer\n",
            "Prediction: negative\n",
            "Confidence: 0.52\n",
            "----------\n",
            "Input: This is really annoying\n",
            "Prediction: negative\n",
            "Confidence: 0.56\n",
            "----------\n",
            "Input: I am just plain fed up\n",
            "Prediction: negative\n",
            "Confidence: 0.57\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "# Display the classification outcomes\n",
        "classes = [\"positive\", \"negative\", \"neutral\"]\n",
        "for inp,pred in zip(inputs, predictions):\n",
        "    class_pred = pred.prediction\n",
        "    class_idx = classes.index(class_pred)\n",
        "    class_conf = pred.confidence\n",
        "\n",
        "    print(f\"Input: {inp}\")\n",
        "    print(f\"Prediction: {class_pred}\")\n",
        "    print(f\"Confidence: {class_conf:.2f}\")\n",
        "    print(\"-\"*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtHkEaLxHql-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
