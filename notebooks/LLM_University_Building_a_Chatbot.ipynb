{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install  cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi8y_Be6nJgI",
        "outputId": "8ca0392e-a390-4c85-d155-8f8575d12c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.13.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.13.0 fastavro-1.9.7 httpx-sse-0.4.0 parameterized-0.9.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere"
      ],
      "metadata": {
        "id": "kzSHCMMVTLa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co = cohere.ClientV2(\"egFS8BVGz1DDbYewbj0Tjzh7fUByUIEzflL2GCsM\")"
      ],
      "metadata": {
        "id": "E09UzaWJTOxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Quickstart"
      ],
      "metadata": {
        "id": "x5Z99SljZQ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#add a message\n",
        "message = \"I'm joining a new startup called Co1t today. Could you help me write an introduction message for my teammates.\"\n",
        "\n",
        "#Generate a response\n",
        "response = co.chat(model=\"command-r-plus-08-2024\", messages= [{\"role\": \"user\",\"content\" : message}])\n",
        "\n",
        "print(response.message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfnS00McTtC4",
        "outputId": "988660b5-595d-4e10-d597-7fd66e009c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a draft of an introduction message for your new colleagues at Co1t:\n",
            "\n",
            "\"Hello everyone!\n",
            "\n",
            "My name is [Your Name], and I am thrilled to introduce myself as the newest member of the Co1t team! Starting my journey here as [Your Role/Position] is an exciting opportunity, and I am eager to contribute to the company's success.\n",
            "\n",
            "A little about myself: I have [mention your relevant experience or background related to the startup's industry]. I am passionate about [list some of your interests or skills related to the job] and believe that my expertise can help drive innovation within the startup environment.\n",
            "\n",
            "Joining Co1t feels like a perfect fit, as I am impressed by the company's vision and the dynamic team culture. I look forward to collaborating with all of you, learning from your unique perspectives, and sharing ideas. Let's connect and discuss ways to make our startup journey a remarkable one!\n",
            "\n",
            "Feel free to reach out if you'd like to grab a coffee (or virtual tea!) and chat further. I'm excited to get to know each of you and build great things together at Co1t.\n",
            "\n",
            "Warm regards,\n",
            "[Your Name]\"\n",
            "\n",
            "Feel free to customize and add any personal touches to make the message align with your style and comfort level. Good luck with your new role, and I hope you have a wonderful first day at Co1t!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Defining a Custom System Message\n",
        "\n",
        "A conversation starts with a system message, or a preamble, to help steer a chatbot’s response toward certain characteristics. For example, if we want the chatbot to adopt a formal style, the preamble can be used to encourage the generation of more business-like and professional responses.\n",
        "\n",
        "The custom system message and the current user message form the prompt to the chatbot\n",
        "\n",
        "In the earlier example, we didn’t have to define a custom system message because a default one was used. We can, however, define our own by adding a message with the system role in the messages array."
      ],
      "metadata": {
        "id": "yVvrDn8WZS1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom system message\n",
        "system_message=\"\"\"\n",
        "\n",
        "## Task and Context\n",
        "You are an assistant who assist new employees of Co1t with their first week.\n",
        "\n",
        "## Style Guide\n",
        "Try to speak in rhymes as much as possible. Be professional.\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\" : system_message},\n",
        "            {\"role\": \"user\", \"content\": message}]"
      ],
      "metadata": {
        "id": "vgxQcm6-Wfnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.chat(model = \"command-r-plus-08-2024\", messages=messages )\n",
        "\n",
        "print(response.message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skzpa7oeaotT",
        "outputId": "bf84d02e-946b-4dc1-9a4f-66abc4dff23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome aboard, a new journey awaits!\n",
            "At Co1t, we're thrilled to have you join our ranks.\n",
            "\n",
            "Here's an introduction, a little verse,\n",
            "To break the ice and quench your thirst.\n",
            "\n",
            "Hello, my new friends, a pleasure to meet,\n",
            "[Your Name] here, ready to greet.\n",
            "I'm excited to embark on this adventure so sweet.\n",
            "With skills [Your expertise or role], I'll contribute to our feat.\n",
            "\n",
            "Let's connect and collaborate, a team so bright,\n",
            "Together, we'll conquer and shine so light.\n",
            "Feel free to reach out, I'm here to lend an ear,\n",
            "Let's make Co1t thrive, and have no fear.\n",
            "\n",
            "A new chapter begins, with a friendly cheer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Streaming the Chatbot Response\n",
        "\n",
        "Our examples so far generate responses in a non-streamed manner. This means that the endpoint would return a response object only after the model has generated the text in full. The longer the text is, the longer it takes to get back the response. If you are building an application, this directly impacts the user’s perception of the application’s latency.\n",
        "\n",
        "The Chat endpoint solves this problem by supporting streamed responses. In a streamed response, the endpoint would return a response object for each token as it is being generated. This means you can display the text incrementally without having to wait for the full completion.\n",
        "\n",
        "To activate it, use co.chat_stream() instead of co.chat()."
      ],
      "metadata": {
        "id": "Fk2YYpocbnNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.chat_stream(model = \"command-r-plus-08-2024\", messages= [{\"role\": \"user\", \"content\": message}])\n",
        "\n",
        "for chunk in response:\n",
        "  if chunk.type == \"content-delta\":\n",
        "    print(chunk.delta.message.content.text, end = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DksfIJZa-R5",
        "outputId": "777afa49-93d6-4e69-d62c-bc136547882f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object V2Client.chat_stream at 0x7bf83a0c0820>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py\", line 27, in run\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a draft of an introduction message for your new colleagues at Co1t:\n",
            "\n",
            "\"Hello everyone!\n",
            "\n",
            "My name is [Your Name], and I am thrilled to introduce myself as the newest member of Team Co1t! I am excited to be joining this innovative startup on its journey to success. As I begin this new chapter, I wanted to take a moment to share a bit about myself.\n",
            "\n",
            "A little background about me: I have always been passionate about [insert relevant field/industry] and have [X years] of experience working in [specific roles or projects related to the industry]. I am particularly interested in [mention any specialized skills or areas of expertise] and am eager to contribute my knowledge to the team. My enthusiasm for [talk about a recent trend or technology in the industry] brought me to Co1t, as I believe the company's vision aligns perfectly with my own aspirations.\n",
            "\n",
            "I am looking forward to collaborating with all of you and learning from your diverse skill sets. One of my strengths is [mention a soft skill or a collaborative approach you excel at], and I hope to utilize this to foster a productive and creative team environment. I'm all ears for any insights or advice as I onboard, and I'm excited to pay it forward to future newcomers.\n",
            "\n",
            "Let's connect and chat more about our goals and ideas! Feel free to reach out via email or schedule a quick introduction call. I can't wait to meet each of you and contribute to the amazing work happening here at Co1t.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\"\n",
            "\n",
            "Feel free to customize and add any personal touches to make the message truly yours. Good luck with your new role, and congratulations on joining Co1t!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Building the Chat History\n",
        "\n",
        "At the core of a conversation is a multi-turn dialog between the user and the chatbot. This requires the chatbot to have a “memory” of all the previous turns to maintain the state of the conversation.\n",
        "\n",
        "The messages list is used to store the conversation history, including both user messages and chatbot responses. It is structured as an array of objects, with each object representing a message in the conversation.\n",
        "\n",
        "By appending the previous response and new user message to messages, the model can access the chat history and generate contextually-aware responses. This allows the chatbot to refer to previous messages and maintain a consistent conversation flow.\n",
        "\n",
        "To illustrate this, let's look at an example. We start with the first conversation turn.\n",
        "\n",
        "Let's also add a custom system message for generating concise response, just to keep the outputs brief for this tutorial."
      ],
      "metadata": {
        "id": "P7GU5SG8dDtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add a user message\n",
        "message = \"I'm joining a new startup called Co1t today. Could you help me write an introduction message for my teammates.\"\n",
        "\n",
        "\n",
        "# Create a custom system message\n",
        "system_message=\"\"\"## Task and Context\n",
        "Generate concise responses, with maximum one-sentence.\"\"\"\n",
        "\n",
        "messages = [  {\"role\": \"user\", \"content\": message},\n",
        "            {\"role\": \"system\",\"content\": system_message} ]\n",
        "\n",
        "\n",
        "response = co.chat(model = \"command-r-plus-08-2024\", messages=messages)\n",
        "\n",
        "print(response.message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgjegvRpeLQC",
        "outputId": "caff74b7-7ce0-447a-d1ee-a7de6b36f7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Hi everyone! I'm thrilled to join Co1t as a new team member, and I look forward to contributing to our shared vision and success.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want the model to refine the earlier response. This requires the next generation to have access to the state, or memory, of the conversation.\n",
        "\n",
        "To do this, we append the message object from the previous response to the messages list.\n",
        "\n",
        "Then we append the next user message to the messages list.\n",
        "\n",
        "Looking at the response, we see that the model is able to get the context from the chat history. The model is able to capture that \"it\" in the user message refers to the introduction message it had generated earlier."
      ],
      "metadata": {
        "id": "Z6p7JqI2f60y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Reset the messages list\n",
        "\n",
        "messages = [  {\"role\": \"user\", \"content\": \"I'm joining a new startup called Co1t today. Could you help me write an introduction message for my teammates.\"},\n",
        "            {\"role\": \"system\",\"content\": \"## Task and Context\\nGenerate concise responses, with maximum one-sentence.\"} ]\n",
        "\n",
        "# Generate the response with the current chat history as the context\n",
        "response = co.chat(model=\"command-r-plus-08-2024\",\n",
        "                   messages=messages)\n",
        "\n",
        "print(response.message.content[0].text)\n",
        "\n",
        "print(\"\\n\")\n",
        "# Append the previous response - ensuring the correct role name\n",
        "messages.append({\"role\": \"assistant\", \"content\": response.message.content})\n",
        "\n",
        "#add the user\n",
        "message = \"make it more upbeat and conversational\"\n",
        "\n",
        "#append the user message\n",
        "messages.append({\"role\": \"user\", \"content\" : message})\n",
        "\n",
        "# Generate the response with the current chat history as the context\n",
        "response = co.chat(model=\"command-r-plus-08-2024\",\n",
        "                   messages=messages)\n",
        "\n",
        "print(response.message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zKHAheVcbui",
        "outputId": "1e2afd61-ff4e-4859-ac4d-342916bffa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Hi everyone! I'm thrilled to join Co1t as a new team member, and I look forward to contributing my skills and collaborating with this talented group.\"\n",
            "\n",
            "\n",
            "\"Hey, Co1t crew! Super excited to be a part of this awesome startup journey. Can't wait to get to know you all and dive into some cool projects together!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can continue doing this for any number of turns by repeating the same steps of appending the chatbot and user messages."
      ],
      "metadata": {
        "id": "ZPAdYV84lQe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the previous response\n",
        "messages.append({'role': 'assistant', 'content': response.message.content})\n",
        "\n",
        "# Add the user message\n",
        "message = \"Thanks. Could you create another one for my DM to my manager.\"\n",
        "\n",
        "# Append the user message\n",
        "messages.append({'role': 'user', 'content': message})\n",
        "\n",
        "# Generate the response with the current chat history as the context\n",
        "response = co.chat(model=\"command-r-plus-08-2024\",\n",
        "                   messages=messages)\n",
        "\n",
        "print(response.message.content[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vbMMhhFi8uE",
        "outputId": "6268d55f-d0cc-4226-ae2a-5e1e8d7e2df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Hey [Manager's Name], just wanted to express my excitement about starting at Co1t. Looking forward to learning and growing under your guidance!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To look at the current chat history, you can print the messages list."
      ],
      "metadata": {
        "id": "SgLPAT2Mlapa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the previous response\n",
        "messages.append({'role': 'assistant', 'content': response.message.content})\n",
        "# View the chat history\n",
        "for message in messages:\n",
        "    print(message,\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F76gZM0glLGr",
        "outputId": "5d7d59c4-956c-46bd-87de-c92e0617de04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'user', 'content': \"I'm joining a new startup called Co1t today. Could you help me write an introduction message for my teammates.\"} \n",
            "\n",
            "{'role': 'system', 'content': '## Task and Context\\nGenerate concise responses, with maximum one-sentence.'} \n",
            "\n",
            "{'role': 'assistant', 'content': [TextAssistantMessageResponseContentItem(type='text', text='\"Hi everyone! I\\'m thrilled to join Co1t as a new team member, and I look forward to contributing my skills and collaborating with this talented group.\"')]} \n",
            "\n",
            "{'role': 'user', 'content': 'make it more upbeat and conversational'} \n",
            "\n",
            "{'role': 'assistant', 'content': [TextAssistantMessageResponseContentItem(type='text', text='\"Hey, Co1t crew! Super excited to be a part of this awesome startup journey. Can\\'t wait to get to know you all and dive into some cool projects together!\"')]} \n",
            "\n",
            "{'role': 'user', 'content': 'Thanks. Could you create another one for my DM to my manager.'} \n",
            "\n",
            "{'role': 'assistant', 'content': [TextAssistantMessageResponseContentItem(type='text', text='\"Hey [Manager\\'s Name], just wanted to express my excitement about starting at Co1t. Looking forward to learning and growing under your guidance!\"')]} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2ZC7DsileE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}